{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c636820f-90da-49b1-b80c-40081c874235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9547a3-a1c9-4bbb-873e-d356fed32e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the check-in data\n",
    "df = pd.read_json('yelp_academic_dataset_checkin.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07d401eb-6bba-4a27-8f51-d03350244fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id                                               date\n",
      "0  ---kPU91CF4Lq2-WlRu9Lw  2020-03-13 21:10:56, 2020-06-02 22:18:06, 2020...\n",
      "1  --0iUa4sNDFiZFrAdIWhZQ  2010-09-13 21:43:09, 2011-05-04 23:08:15, 2011...\n",
      "2  --30_8IhuyMHbSOcNWd6DQ           2013-06-14 23:29:17, 2014-08-13 23:20:22\n",
      "3  --7PUidqRWpRSpXebiyxTg  2011-02-15 17:12:00, 2011-07-28 02:46:10, 2012...\n",
      "4  --7jw19RH9JKXgFohspgQw  2014-04-21 20:42:11, 2014-04-28 21:04:46, 2014...\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c02a278-e2f3-4d2c-b48f-733774781cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Parse and explode timestamp lists\n",
    "df['date'] = df['date'].apply(lambda x: x.split(', ') if isinstance(x, str) else [])\n",
    "df_exploded = df.explode('date')\n",
    "df_exploded['date'] = pd.to_datetime(df_exploded['date'], errors='coerce')\n",
    "\n",
    "# Step 3: Extract day of week\n",
    "df_exploded['day_of_week'] = df_exploded['date'].dt.day_name()\n",
    "\n",
    "# Step 4: Aggregate to compact format\n",
    "compact_df = (\n",
    "    df_exploded.groupby('business_id')\n",
    "    .agg(\n",
    "        total_checkins=('date', 'count'),\n",
    "        first_checkin=('date', 'min'),\n",
    "        last_checkin=('date', 'max')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Step 5: Get day-wise check-in counts\n",
    "checkins_by_day = (\n",
    "    df_exploded.groupby(['business_id', 'day_of_week'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Step 6: Merge day-of-week counts into the compact summary\n",
    "compact_df = pd.merge(compact_df, checkins_by_day, on='business_id', how='left')\n",
    "\n",
    "# Optional: Fill missing weekday columns with 0\n",
    "weekday_columns = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "for day in weekday_columns:\n",
    "    if day not in compact_df.columns:\n",
    "        compact_df[day] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ccaa601-7f4a-447f-972b-dd311dc5d48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id  total_checkins       first_checkin  \\\n",
      "0  ---kPU91CF4Lq2-WlRu9Lw              11 2020-03-13 21:10:56   \n",
      "1  --0iUa4sNDFiZFrAdIWhZQ              10 2010-09-13 21:43:09   \n",
      "2  --30_8IhuyMHbSOcNWd6DQ               2 2013-06-14 23:29:17   \n",
      "3  --7PUidqRWpRSpXebiyxTg              10 2011-02-15 17:12:00   \n",
      "4  --7jw19RH9JKXgFohspgQw              26 2014-04-21 20:42:11   \n",
      "\n",
      "         last_checkin  Friday  Monday  Saturday  Sunday  Thursday  Tuesday  \\\n",
      "0 2021-11-11 16:23:50       4       0         2       0         1        2   \n",
      "1 2014-04-12 23:04:47       1       4         1       0         0        2   \n",
      "2 2014-08-13 23:20:22       1       0         0       0         0        0   \n",
      "3 2015-09-27 13:18:32       1       1         1       2         2        3   \n",
      "4 2021-06-21 19:59:50       0       9         0       1         9        5   \n",
      "\n",
      "   Wednesday  \n",
      "0          2  \n",
      "1          2  \n",
      "2          1  \n",
      "3          0  \n",
      "4          2  \n"
     ]
    }
   ],
   "source": [
    "print(compact_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "303c27aa-3064-40e3-95f0-f28ddc9053c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='yelp_business_checkins_transformed.csv' target='_blank'>yelp_business_checkins_transformed.csv</a><br>"
      ],
      "text/plain": [
       "/Users/abhishekkumar/Downloads/Yelp JSON/yelp_business_checkins_transformed.csv"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Save the cleaned DataFrame to a JSON file in the current working directory\n",
    "compact_df.to_csv('yelp_business_checkins_transformed.csv')\n",
    "print(\"Hello\")\n",
    "# Create a download link for the JSON file\n",
    "FileLink('yelp_business_checkins_transformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe2e641-4d3a-492a-a4fc-de46d543818b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
